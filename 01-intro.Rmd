
#  Introduction {#intro}

> We start with a certain problem, and I find myself drawing 
> pictures of the problem before we ever get abstract.
> Youâ€™re trying to make the problem concrete before 
> you translate it into the abstract.
> 
> `r tufte::quote_footer('--- in A Conversation with Leo Breiman [@Olshen:2001aa]')`


The inspiration for this manual comes from 
lecture notes in applied statistics from a course
taught at the UC, Berkeley statistics department in 1991,
and from the author of these notes, Professor Leo Breiman.

In 2001, in an article titled **Statistical Modeling: The Two Cultures**
[@Breiman:2001aa], Leo Breiman called out the statistical community for
being ill-equipped to tackle the data analytical challenges
of the day.  Some 14 years later
the field of statistics appeared to finally be shaken out of its lull
as many were asking where the field of statistics was going, or not going rather.
In **50 Years of Data Science** [@Donoho:2017aa],
Breiman's urging academic statistics to expand its boundaries
beyond the classical domain of theoretical statistics is recognized 
along with similar callings coming from contemporaries 
John Chambers [@Chambers1993GreaterOL], 
Jeff Wu (slides [here](http://www2.isye.gatech.edu/~jeffwu/presentations/datascience.pdf)),
and Bill Cleveland [@Cleveland:2001aa]
as well as from their predecessor, John Tukey [@Tukey:1962aa]^[
Analysts at XXX should recognize John Tukey as the inventor
of the most utilized data display tool in the company.]
, some 50 years before them.  For the period running from 2001 to 2014, 
Semantic Scholar recorded 639 citations to the **Two Cultures** paper.
Since 2014, Semantic Scholar recorded 2603 citations.
References in the web are countless.  Almost all of the discussion of the paper has to
do with the main point of the paper - the predictive versus the data modeling approach to
data analysis.

In addition to calling out the divide between the two cultures in terms 
of suitability for tackling modern day problems, in his
2001 manifesto Leo Breiman also points out that even when the data modeling approach
is appropriate, statisticians are ill-prepared to solve these problems because of the
**training by technique** taught in schools and consequent misuses of these in practice
leading practitioners to view the role of the statistician as one of finding the
most appropriate pre-defined technique to solve a problem, rather than trying to 
solve the problem directly^[
a point which he made in a 1984 technical report
titled **Nail Finders, The Edifice Complex and Oz**  [@Breiman:1984aa].].
The significance of this criticism of common statistical practice
has been ignored by most^[
In his comments on The Two Cultures, Sir David Cox expressed skepticism
regarding the claim of pervasive routinization of statistical analysis in practice.
We can argue about the meaning of "pervasive" and "routinization" but I personally
have not witnessed many examples of deep thought in statistical practice, nor
much demand for it - the consumers of statistical analysis are commonly in need
of a report required for some sort of compliance or in support of an hypothessis
they already believe to be true.  ie. Nobody has skin in the game, so to speak.
Nobody is betting personal assets on the outcome of the statiscial analysis,
and most have more to lose from inaction than from acting on bad information.].


While teaching the class the theoretical foundations of applied statistics, Professor
Breiman often reminded us to focus on the problem; not the technique, and
to clearly **identify the sources of variability** rather than accept that the variability
assumed by any standard model is adequate.  He was urging the students to think;
not follow recipes.   This is central dogma of this monograph: **think before you stat**.


---

Leo Breiman's career followed a very interesting and unusual path.
He left an academic post as a theoretical probabilist to earn
a living as a consultant while teaching mathematics to kids from Mexico. 
In doing so he became deeply interested in the education system.
He ran for and was elected to the Santa Monica School Board and
soon after became its president.  While he was 
"having a wonderful time consulting... 
solving real problems, working with data", 
he was offered a faculty position
in the Department of Statistics at UC, Berkeley,
which he accepted [@Cutler:2010aa;@Olshen:2001aa]^[
The conversation with Richard Olshen is extremely
interesting and makes for a fascinating short tread.]. 

<br/>

## Nail Finders, The Edifice Complex and Oz 

A short time after returning to academics, Professor
Breiman wrote an interesting paper titled
"Nail Finders, Edifices, and Oz" [@Breiman:1984aa].
He writes:

> The thesis of this paper is that many, if not most,
> statisticians in government and industry are poorly
> trained for their profession with the result that they
> are poor problem solvers ...


While we may disagree as to whether or not statisticians 
deserve this characterization, we have to agree that the
traits described in the paper are best avoided - the find-the-nail, 
edifice and Oz complex.


* The find-the-nail complex

> If all you have is a hammer, then every problem 
> will look like a nail.
>
> `r tufte::quote_footer('--- Jerome Freidman saying (source unknown) [@Breiman:1984aa]')`
 
Applied to statisticians, this refers to *absorption* with the technique
(unhealthy infatuation with models?) rather than with the problem;
"the failure to see the problem whole; to ask, *Does it all make sense?*",
and, dare I say,  "where's the randomness coming from".

Are statisticians nail-finders?  How many of us have encountered survival data
at work and Not used the Cox proportional hazards model to analyze the data?
How many of us have used something other than logistic or probit
regression to analyze data when the outcome is dichotomous.
In some cases these techniques are appropriate,
but there must be numerous cases when some other approach would be 
preferable, but never considered.

The nail finder syndrome is encouraged to a large extent 
by the usual textbook format
which includes neat examples associated with each introduced technique.
This format leads to the belief that there is
a ready-made canned solution for every problem.  In this modus operandi,
little to no effort is spent trying to get to a deep understanding of the
problem at hand, and the data to help solve the problem;
one only tries to characterize the problem
to the extent necessary to find a suitably well matched canned solution.

In laying out these notes we will avoid this format.  Case studies in
data analysis will be laid out in separate sections with no connection 
to the notes sections, some of which do introduce specific
analysis methods.


* The edifice complex 

This refers to the building of a large, elaborate and many 
layered statistical analysis often covering up what is simple and
obvious.*

Another trap best avoided  - inventing complexity when there isn't any.
Not every problem presented to a statistician requires statistical
methodologies for their solution.  In some cases the solution may reveal itself
in a plot or in a sketch which captures the essence of the problem.


* The Wizard of Oz Complex

*The exploitation of the mysteries of statistics to dazzle and mystify
the less knowledgable.* 


This calls for a little break: 

```{r, echo=F, eval=F}
knitr::include_url("https://www.youtube.com/embed/8ZYG2PCyNfE", height="200px")
```

<iframe width="560" height="315" src="https://www.youtube.com/embed/8ZYG2PCyNfE" title="Give them the old Razzle Dazzle" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

**Include illustrations of the above - open contributions from XXXers**


<br/>


## Where's the randomness? 


> In God we trust.
> All others, bring data and
> Leave your beliefs at the door^[
It is just too taxing to verify repeatability
which only occurs in an alternate universe.].
> 
> `r tufte::quote_footer('--- adapted from W. Edwards Deming')`

Against this background for the need of change, when we enter
Leo Breiman's classroom we enter a world deeply 
steeped in the theoretical underpinnings of 
applied statistics.  Although all of the necessary theory was
included in the course material, we spent very little time 
marvelling at the beauty of the mathematical results
underlying some statistical theories (for example ...) and instead
were encouraged and challenged to struggle with 
difficult questions: what happens if this assumption is not true?
or that assumption? I remember one particular lecture watching Professor  Breiman
repeating the mantra "**where is the randomness? 
where's the randomness coming from**?" while pacing up and down the front of the class.

Some 30 years later, faced with the problem of trying to answer questions
about a system generating data which comes in the form of batches of points
having a yet to be fully understood correlation structure, and subject to
sporadic surges of variation of unknown origin, Professor Breiman's words
reverberate in my head.  I now fully appreciate the relevance of the question -
**where's the randomness coming from**.  I don't think there is
any exaggeration in claiming that if we can identify the relevant sources of variability, 
and how to capture them in an analysis dataset, 
we have basically fully solved the data analytic problem: we know exactly
what data to collect and how to summarize them in order to
answer the question of interest.

<br/>

## What next?  

> If the doors of perception were cleansed
> every thing would appear to man as it is, Infinite
>
> `r tufte::quote_footer('--- William Blake, The Marriage of Heaven and Hell (1790)')`  

### The theory {-} 

The plan is to go through professor Breiman's notes
and to connect the principles and questions
raised to problems we face, thinking about the data 
and sources of variability - where is the 
randomness coming from.
Having gone through these notes, we should be convinced
of the truth of this idiom, and this in turn will provide the 
motivation and drive necessary to get to a full and accurate knowledge 
of the randomness present in the task at hand:
there should never be any guessing or nonchalant
presuming involved - the case for any assumed  randomness in a data model
must be made explicitly^[
This is especially true when we quote p-values.  This is important
and a separate section will be devoted to a discussion of p-values.].
With this practice we can gain an  appropriate level of confidence in the results
that we gather to be true, and we  should only have to deal with risks
coming from well understood variability.  Unexpected surprises
will become the exception rather than the rule.  This is the dream,
and it remains a dream while we follow recipes and deliver
ready-made *solutions* rather than tackle problems with an appropriate
measure of ingenuity and perseverance.  


Professor Breiman's class notes provide the statistical theory
necessary to move forward with most data analysis projects.
This may be a minimalists' point of view in terms of 
required statistical theory background;
we will see as we work through some problems.


<!--
themselves in the course of our work will lend themselves to analysis
using traditional and more or less standard linear modeling statistical
techniques, many,  if not all, will have unique features - 
randomness in the data, application or question of interest,  and
inferential frame.  Identifying the unique features present of the task
at hand is the primary role of the statistical analyst.
If there are no new features to a new problem, leave it to AI or
change the link to the input in last weeks' code, push go,
and turn your attention to the next problem which requires careful
consideration and may call for some innovation and ingenuity.  
-->

<br/>

### The practice {-}

Leo Breiman firmly believed that **statistics is about solving problems**.  We would
not be doing justice to his legacy if we just went through his notes which describe
some helpful theory whose only relevance in Professor Breiman's mind was to provide
tools to solve problems.  With that in mind the essential content of this manuscript
will not be the notes on theory, but **the illustration of applied statistics at work** 
in solving problems.  The task is therefore to include numerous case studies
illustrating good data analysis practice.  

To be determined is the lay-out - where to insert the case studies.
One thing is certain: we have to avoid the usual format of attaching
examples to techniques as they are introduced.  The usual textbook 
format which ties trivial, neat examples to technique 
as each new technique is introduced 
leads to an unduly strong association between problem and technique,
and to the belief that matching problems to textbook technique is the
crunch of statistical analysis^[
This is not quite the nail-finder's syndrome, but a close relative -
the tool-finder syndrome.  The latter retains the tendency to 
work around the essential task of becoming intimately familiar
with the substance of the problem before trying to solve it.].
What we will endeaver to realize is to fill this document
with detailed reports of data design, collection and analyses which
are inspiring and can be shown to have the attibutes of dependability and durability.

--- Stat Student
